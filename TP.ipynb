{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ce0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiron\\.cache\\kagglehub\\datasets\\adisongoh\\it-service-ticket-classification-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"adisongoh/it-service-ticket-classification-dataset\")\n",
    "\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a41c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Document  \\\n",
      "0  connection with icon icon dear please setup ic...   \n",
      "1  work experience user work experience user hi w...   \n",
      "2  requesting for meeting requesting meeting hi p...   \n",
      "3  reset passwords for external accounts re expir...   \n",
      "4  mail verification warning hi has got attached ...   \n",
      "\n",
      "                                        cleaned_text    Topic_group  \n",
      "0  connection icon icon dear setup icon icon engi...       Hardware  \n",
      "1  work experience user work experience user hi w...         Access  \n",
      "2  request meeting request meeting hi help follow...       Hardware  \n",
      "3  reset password external account expire day hi ...         Access  \n",
      "4  mail verification warning hi got attach addres...  Miscellaneous  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"all_tickets_processed_improved_v3.csv\")\n",
    "\n",
    "# if fail python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a cleaning function\n",
    "def clean_text(text):\n",
    "    # remove non letter\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    # lemmatize and remove stopwords/punctuation/single characters\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop and len(token) > 1]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"Document\"].apply(clean_text)\n",
    "print(df[[\"Document\", \"cleaned_text\", \"Topic_group\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646f2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"Document\"].fillna(\"\").tolist()\n",
    "\n",
    "# Batch process with nlp.pipe\n",
    "cleaned_texts = []\n",
    "for doc in nlp.pipe(texts, batch_size=50, n_process=4):  # Set n_process >1 if spaCy v3 and multiprocessing is supported\n",
    "    # Lowercase and remove non-letter characters\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop and len(token) > 1]\n",
    "    cleaned_texts.append(\" \".join(tokens))\n",
    "\n",
    "# Add back to dataframe\n",
    "df[\"cleaned_text_bis\"] = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ab42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # You can tweak max_features\n",
    "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
    "\n",
    "# labels\n",
    "y = df[\"Topic_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18b5b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Access       0.91      0.87      0.89      1455\n",
      "Administrative rights       0.88      0.67      0.76       342\n",
      "           HR Support       0.83      0.82      0.83      2107\n",
      "             Hardware       0.79      0.88      0.83      2760\n",
      "     Internal Project       0.91      0.78      0.84       451\n",
      "        Miscellaneous       0.79      0.83      0.81      1400\n",
      "             Purchase       0.97      0.88      0.92       497\n",
      "              Storage       0.92      0.84      0.87       556\n",
      "\n",
      "             accuracy                           0.84      9568\n",
      "            macro avg       0.88      0.82      0.84      9568\n",
      "         weighted avg       0.84      0.84      0.84      9568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be7ad4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ticket_classifier_api/model/vectorizer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# save classifier and vectorizer\n",
    "joblib.dump(clf, \"ticket_classifier_api/model/classifier.pkl\")\n",
    "joblib.dump(vectorizer, \"ticket_classifier_api/model/vectorizer.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
